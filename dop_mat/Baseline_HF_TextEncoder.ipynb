{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: open_clip_torch in /usr/local/lib/python3.9/dist-packages (2.23.0)\n",
      "Collecting pytorch_lightning\n",
      "  Downloading pytorch_lightning-2.1.0-py3-none-any.whl (774 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.6/774.6 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from open_clip_torch) (0.13.1+cu116)\n",
      "Requirement already satisfied: ftfy in /usr/local/lib/python3.9/dist-packages (from open_clip_torch) (6.1.1)\n",
      "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from open_clip_torch) (1.12.1+cu116)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from open_clip_torch) (4.64.1)\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.9/dist-packages (from open_clip_torch) (0.9.8)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from open_clip_torch) (3.19.6)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.9/dist-packages (from open_clip_torch) (0.12.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from open_clip_torch) (0.1.97)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from open_clip_torch) (2022.10.31)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (23.0)\n",
      "Collecting torchmetrics>=0.7.0\n",
      "  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (4.4.0)\n",
      "Collecting lightning-utilities>=0.8.0\n",
      "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (1.23.4)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (2023.1.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.28.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.9/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.3)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.9/dist-packages (from ftfy->open_clip_torch) (0.2.6)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->open_clip_torch) (3.9.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.9/dist-packages (from timm->open_clip_torch) (0.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->open_clip_torch) (9.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (18.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2019.11.28)\n",
      "Installing collected packages: lightning-utilities, torchmetrics, pytorch_lightning\n",
      "Successfully installed lightning-utilities-0.9.0 pytorch_lightning-2.1.0 torchmetrics-1.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install open_clip_torch pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel,AutoTokenizer\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "import open_clip\n",
    "pl.seed_everything(56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov  2 20:40:13 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  Off  | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   56C    P0    82W / 300W |   1139MiB / 81920MiB |      3%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RN50', 'openai'),\n",
       " ('RN50', 'yfcc15m'),\n",
       " ('RN50', 'cc12m'),\n",
       " ('RN50-quickgelu', 'openai'),\n",
       " ('RN50-quickgelu', 'yfcc15m'),\n",
       " ('RN50-quickgelu', 'cc12m'),\n",
       " ('RN101', 'openai'),\n",
       " ('RN101', 'yfcc15m'),\n",
       " ('RN101-quickgelu', 'openai'),\n",
       " ('RN101-quickgelu', 'yfcc15m'),\n",
       " ('RN50x4', 'openai'),\n",
       " ('RN50x16', 'openai'),\n",
       " ('RN50x64', 'openai'),\n",
       " ('ViT-B-32', 'openai'),\n",
       " ('ViT-B-32', 'laion400m_e31'),\n",
       " ('ViT-B-32', 'laion400m_e32'),\n",
       " ('ViT-B-32', 'laion2b_e16'),\n",
       " ('ViT-B-32', 'laion2b_s34b_b79k'),\n",
       " ('ViT-B-32', 'datacomp_xl_s13b_b90k'),\n",
       " ('ViT-B-32', 'datacomp_m_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_clip_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_laion_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_image_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_text_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_basic_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_s128m_b4k'),\n",
       " ('ViT-B-32', 'datacomp_s_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_clip_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_laion_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_image_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_text_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_basic_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_s13m_b4k'),\n",
       " ('ViT-B-32-256', 'datacomp_s34b_b86k'),\n",
       " ('ViT-B-32-quickgelu', 'openai'),\n",
       " ('ViT-B-32-quickgelu', 'laion400m_e31'),\n",
       " ('ViT-B-32-quickgelu', 'laion400m_e32'),\n",
       " ('ViT-B-32-quickgelu', 'metaclip_400m'),\n",
       " ('ViT-B-32-quickgelu', 'metaclip_fullcc'),\n",
       " ('ViT-B-16', 'openai'),\n",
       " ('ViT-B-16', 'laion400m_e31'),\n",
       " ('ViT-B-16', 'laion400m_e32'),\n",
       " ('ViT-B-16', 'laion2b_s34b_b88k'),\n",
       " ('ViT-B-16', 'datacomp_xl_s13b_b90k'),\n",
       " ('ViT-B-16', 'datacomp_l_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_clip_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_laion_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_image_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_text_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_basic_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_s1b_b8k'),\n",
       " ('ViT-B-16-quickgelu', 'metaclip_400m'),\n",
       " ('ViT-B-16-quickgelu', 'metaclip_fullcc'),\n",
       " ('ViT-B-16-plus-240', 'laion400m_e31'),\n",
       " ('ViT-B-16-plus-240', 'laion400m_e32'),\n",
       " ('ViT-L-14', 'openai'),\n",
       " ('ViT-L-14', 'laion400m_e31'),\n",
       " ('ViT-L-14', 'laion400m_e32'),\n",
       " ('ViT-L-14', 'laion2b_s32b_b82k'),\n",
       " ('ViT-L-14', 'datacomp_xl_s13b_b90k'),\n",
       " ('ViT-L-14', 'commonpool_xl_clip_s13b_b90k'),\n",
       " ('ViT-L-14', 'commonpool_xl_laion_s13b_b90k'),\n",
       " ('ViT-L-14', 'commonpool_xl_s13b_b90k'),\n",
       " ('ViT-L-14-quickgelu', 'metaclip_400m'),\n",
       " ('ViT-L-14-quickgelu', 'metaclip_fullcc'),\n",
       " ('ViT-L-14-336', 'openai'),\n",
       " ('ViT-H-14', 'laion2b_s32b_b79k'),\n",
       " ('ViT-H-14-quickgelu', 'metaclip_fullcc'),\n",
       " ('ViT-g-14', 'laion2b_s12b_b42k'),\n",
       " ('ViT-g-14', 'laion2b_s34b_b88k'),\n",
       " ('ViT-bigG-14', 'laion2b_s39b_b160k'),\n",
       " ('roberta-ViT-B-32', 'laion2b_s12b_b32k'),\n",
       " ('xlm-roberta-base-ViT-B-32', 'laion5b_s13b_b90k'),\n",
       " ('xlm-roberta-large-ViT-H-14', 'frozen_laion5b_s13b_b90k'),\n",
       " ('convnext_base', 'laion400m_s13b_b51k'),\n",
       " ('convnext_base_w', 'laion2b_s13b_b82k'),\n",
       " ('convnext_base_w', 'laion2b_s13b_b82k_augreg'),\n",
       " ('convnext_base_w', 'laion_aesthetic_s13b_b82k'),\n",
       " ('convnext_base_w_320', 'laion_aesthetic_s13b_b82k'),\n",
       " ('convnext_base_w_320', 'laion_aesthetic_s13b_b82k_augreg'),\n",
       " ('convnext_large_d', 'laion2b_s26b_b102k_augreg'),\n",
       " ('convnext_large_d_320', 'laion2b_s29b_b131k_ft'),\n",
       " ('convnext_large_d_320', 'laion2b_s29b_b131k_ft_soup'),\n",
       " ('convnext_xxlarge', 'laion2b_s34b_b82k_augreg'),\n",
       " ('convnext_xxlarge', 'laion2b_s34b_b82k_augreg_rewind'),\n",
       " ('convnext_xxlarge', 'laion2b_s34b_b82k_augreg_soup'),\n",
       " ('coca_ViT-B-32', 'laion2b_s13b_b90k'),\n",
       " ('coca_ViT-B-32', 'mscoco_finetuned_laion2b_s13b_b90k'),\n",
       " ('coca_ViT-L-14', 'laion2b_s13b_b90k'),\n",
       " ('coca_ViT-L-14', 'mscoco_finetuned_laion2b_s13b_b90k'),\n",
       " ('EVA01-g-14', 'laion400m_s11b_b41k'),\n",
       " ('EVA01-g-14-plus', 'merged2b_s11b_b114k'),\n",
       " ('EVA02-B-16', 'merged2b_s8b_b131k'),\n",
       " ('EVA02-L-14', 'merged2b_s4b_b131k'),\n",
       " ('EVA02-L-14-336', 'merged2b_s6b_b61k'),\n",
       " ('EVA02-E-14', 'laion2b_s4b_b115k'),\n",
       " ('EVA02-E-14-plus', 'laion2b_s9b_b144k'),\n",
       " ('ViT-B-16-SigLIP', 'webli'),\n",
       " ('ViT-B-16-SigLIP-256', 'webli'),\n",
       " ('ViT-B-16-SigLIP-i18n-256', 'webli'),\n",
       " ('ViT-B-16-SigLIP-384', 'webli'),\n",
       " ('ViT-B-16-SigLIP-512', 'webli'),\n",
       " ('ViT-L-16-SigLIP-256', 'webli'),\n",
       " ('ViT-L-16-SigLIP-384', 'webli'),\n",
       " ('ViT-SO400M-14-SigLIP', 'webli'),\n",
       " ('ViT-SO400M-14-SigLIP-384', 'webli'),\n",
       " ('ViT-L-14-CLIPA', 'datacomp1b'),\n",
       " ('ViT-L-14-CLIPA-336', 'datacomp1b'),\n",
       " ('ViT-H-14-CLIPA', 'datacomp1b'),\n",
       " ('ViT-H-14-CLIPA-336', 'laion2b'),\n",
       " ('ViT-H-14-CLIPA-336', 'datacomp1b'),\n",
       " ('ViT-bigG-14-CLIPA', 'datacomp1b'),\n",
       " ('ViT-bigG-14-CLIPA-336', 'datacomp1b'),\n",
       " ('nllb-clip-base', 'v1'),\n",
       " ('nllb-clip-large', 'v1')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_clip.list_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    wandb=False\n",
    "    num_workers=8\n",
    "    model=\"ViT-B-16-SigLIP\"\n",
    "    pretrained = \"webli\"\n",
    "    text_encoder = 'ai-forever/ruBert-base'\n",
    "    #model = 'ViT-B-32'\n",
    "    #pretrained = 'commonpool_m_clip_s128m_b4k'\n",
    "    hidden_size = 768 * 2\n",
    "    train_path='./train-test-csvs/train-7.csv'\n",
    "    test_path = './train-test-csvs/test-5.csv'\n",
    "    val_split_size = 0.2\n",
    "    num_labels = 8\n",
    "    scheduler='cosine'\n",
    "    max_epoches=1\n",
    "    clip_lr = 4e-6\n",
    "    mlp_lr = 2e-4\n",
    "    text_lr = 3e-5\n",
    "    eps=1e-6\n",
    "    weights_decay=0.01\n",
    "    batch_size=16\n",
    "    seed=56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df,preprocess,tokenizer):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG()\n",
    "        self.data = df[['image','label','text']]\n",
    "        self.data = self.data.values\n",
    "        self.processor = preprocess\n",
    "        self.tokenizer = tokenizer\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.data[index][0])\n",
    "        image = self.processor(image)\n",
    "        text_encoding = self.tokenizer.encode_plus(self.data[index][2],\n",
    "                                                   padding='max_length',\n",
    "                                                   truncation=True,\n",
    "                                                   max_length=48,\n",
    "                                                   return_tensors='pt')\n",
    "        label = self.data[index][1]\n",
    "        return {'image':image,\n",
    "                'text_ids':text_encoding.input_ids[0],\n",
    "                'attention_mask':text_encoding.attention_mask[0],\n",
    "                'label':label}\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "label_vc = {'Развлечения и юмор':0,\n",
    "            'Кулинария':1,\n",
    "            'Торговля и объявления':2,\n",
    "            'СМИ':3,\n",
    "            'Философия и религия':4,\n",
    "            'Животные':5,\n",
    "            'Творчество и дизайн':6,\n",
    "            'Путешествия':7}\n",
    "\n",
    "def process_labels(label):\n",
    "    if label not in label_vc.keys():\n",
    "        return -1\n",
    "    else:\n",
    "        return label_vc[label]\n",
    "def process_text(text:str):\n",
    "    return text.strip().lower()\n",
    "\n",
    "def make_df(path):\n",
    "    df = pd.DataFrame()\n",
    "    data = pd.read_csv(path,sep=';')\n",
    "    if 'label' in data.columns:\n",
    "        data['label'] = data['label'].map(process_labels)\n",
    "        data = data[data['label'] != -1].reset_index()\n",
    "        df['text'] = data[data['label'] != -1]['description'].fillna('')\n",
    "        df['label'] = le.fit_transform(data['label'])\n",
    "        df['image'] = data['id'].map(lambda x:'./vseros-final-data/Data/Train/'+str(x))\n",
    "    else:\n",
    "        df['label'] = 0\n",
    "        df['text'] = data['description'].fillna('')\n",
    "        df['image'] = data['id'].map(lambda x:'./vseros-final-data/Data/Test/'+str(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,processor,tokenizer):\n",
    "        super().__init__()\n",
    "        self.processor = processor\n",
    "        self.tokenizer = tokenizer\n",
    "        self.cfg = CFG()\n",
    "        self.train_dataset_path = self.cfg.train_path\n",
    "        self.test_dataset_path = self.cfg.test_path\n",
    "        self.val_split_size = self.cfg.val_split_size\n",
    "        self.batch_size = self.cfg.batch_size\n",
    "        self.num_workers = self.cfg.num_workers\n",
    "        self.is_setup = False\n",
    "    def prepare_data(self):\n",
    "        self.train_df = make_df(self.train_dataset_path)\n",
    "        self.test_df = make_df(self.test_dataset_path)\n",
    "    def setup(self, stage: str):\n",
    "        if self.is_setup:\n",
    "            return None\n",
    "        self.train_df, self.val_df = train_test_split(self.train_df, test_size=self.val_split_size,random_state=self.cfg.seed)\n",
    "        self.train_dataset = PLDataset(self.train_df,self.processor,self.tokenizer)\n",
    "        self.val_dataset = PLDataset(self.val_df,self.processor,self.tokenizer)\n",
    "        self.predict_dataset = PLDataset(self.test_df,self.processor,self.tokenizer)\n",
    "        self.is_setup = True\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train_dataset,\n",
    "                                           batch_size=self.batch_size,\n",
    "                                           num_workers=self.num_workers,\n",
    "                                           shuffle=True)\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.val_dataset,\n",
    "                                           batch_size=self.batch_size,\n",
    "                                           num_workers=self.num_workers)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.predict_dataset,\n",
    "                                           batch_size=self.batch_size,\n",
    "                                           num_workers=self.num_workers,\n",
    "                                           shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLModule(pl.LightningModule):\n",
    "    def __init__(self,clip,bert):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG()\n",
    "        self.clip = clip\n",
    "        self.text_model = bert\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.cfg.hidden_size,self.cfg.hidden_size * 2),\n",
    "                                 nn.LayerNorm(self.cfg.hidden_size * 2),\n",
    "                                 nn.GELU(),\n",
    "                                 nn.Linear(self.cfg.hidden_size * 2,self.cfg.num_labels))\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.pool = MeanPooling()\n",
    "        self.val_targets = []\n",
    "        self.val_preds = []\n",
    "        self.get_features = False\n",
    "        \n",
    "    def get_clip_features(self,batch):\n",
    "        image_features = self.clip.encode_image(batch['image'])\n",
    "        text_features = self.text_model(batch['text_ids'],\n",
    "                                        attention_mask=batch['attention_mask'])['last_hidden_state']\n",
    "        text_features = self.pool(text_features,batch['attention_mask'])\n",
    "        return torch.cat([image_features,text_features],axis=-1)\n",
    "    def forward(self,batch):\n",
    "        features = self.get_clip_features(batch)\n",
    "        return self.mlp(features)\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        logits = self(batch)\n",
    "        loss = self.criterion(logits, batch['label'])\n",
    "        return loss\n",
    "        \n",
    "    def validation_step(self, batch, _):\n",
    "        logits = self(batch).argmax(dim=-1).cpu().detach().tolist()\n",
    "        self.val_targets += batch['label'].tolist()\n",
    "        self.val_preds += logits\n",
    "        \n",
    "    def predict_step(self, batch, _):\n",
    "        x1,x2,_ = batch\n",
    "        if not self.get_features:\n",
    "            logits = self(x1,x2).argmax(dim=-1).cpu().detach().tolist()\n",
    "            return logits\n",
    "        else:\n",
    "            features = self.get_clip_features(x1,x2).cpu().detach().tolist()\n",
    "            return features\n",
    "        \n",
    "    def calc_metric(self):\n",
    "        return 100 * (f1_score(self.val_targets,self.val_preds,average='macro'))\n",
    "        \n",
    "    def on_validation_epoch_end(self):\n",
    "        print(self.calc_metric())\n",
    "        self.val_targets, self.val_preds = [],[]\n",
    "            \n",
    "    def configure_optimizers(self):\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in self.clip.visual.named_parameters()],\n",
    "                \"lr\": self.cfg.clip_lr\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in self.text_model.named_parameters()],\n",
    "                \"lr\": self.cfg.clip_lr\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in self.mlp.named_parameters()],\n",
    "                \"lr\": self.cfg.mlp_lr\n",
    "            }\n",
    "        ]\n",
    "        return torch.optim.AdamW(optimizer_grouped_parameters,\n",
    "                                 weight_decay=self.cfg.weights_decay\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clip, _, preprocess = open_clip.create_model_and_transforms(CFG.model, pretrained=CFG.pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ai-forever/ruBert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert = AutoModel.from_pretrained(CFG.text_encoder)\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.text_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dm = PLDataModule(preprocess,tokenizer)\n",
    "dm.prepare_data()\n",
    "dm.setup(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_pl = PLModule(clip,bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval='epoch')\n",
    "checkpoint_cb = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath='./outputs/',\n",
    "    filename='model_{epoch:02d}-{val_acc:.4f}',\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    precision=32,\n",
    "    min_epochs=1,\n",
    "    check_val_every_n_epoch=1,\n",
    "    max_epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type             | Params\n",
      "------------------------------------------------\n",
      "0 | clip       | CustomTextCLIP   | 203 M \n",
      "1 | text_model | BertModel        | 178 M \n",
      "2 | mlp        | Sequential       | 4.8 M \n",
      "3 | criterion  | CrossEntropyLoss | 0     \n",
      "4 | pool       | MeanPooling      | 0     \n",
      "------------------------------------------------\n",
      "386 M     Trainable params\n",
      "0         Non-trainable params\n",
      "386 M     Total params\n",
      "1,544.863 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.292517006802721\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e543c6143d9a43238000986bb23b72fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.14589395522628\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.87668074750547\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.85470501685974\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.87569018995427\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.78031232382189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model_pl,datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T16:36:30.623136Z",
     "iopub.status.busy": "2023-07-14T16:36:30.622725Z",
     "iopub.status.idle": "2023-07-14T16:37:10.405880Z",
     "shell.execute_reply": "2023-07-14T16:37:10.404604Z",
     "shell.execute_reply.started": "2023-07-14T16:36:30.623100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7c5851ec7849b1834bd4a4686aeaa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_preds = trainer.predict(model_pl,datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T16:37:17.768436Z",
     "iopub.status.busy": "2023-07-14T16:37:17.767996Z",
     "iopub.status.idle": "2023-07-14T16:37:17.775830Z",
     "shell.execute_reply": "2023-07-14T16:37:17.774714Z",
     "shell.execute_reply.started": "2023-07-14T16:37:17.768380Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T16:37:18.059174Z",
     "iopub.status.busy": "2023-07-14T16:37:18.058783Z",
     "iopub.status.idle": "2023-07-14T16:37:18.088758Z",
     "shell.execute_reply": "2023-07-14T16:37:18.087727Z",
     "shell.execute_reply.started": "2023-07-14T16:37:18.059143Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "df['label'] = np.sum(test_preds)\n",
    "df['id'] = pd.read_csv(CFG.test_path,sep=';').id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T16:37:19.066294Z",
     "iopub.status.busy": "2023-07-14T16:37:19.065529Z",
     "iopub.status.idle": "2023-07-14T16:37:19.074423Z",
     "shell.execute_reply": "2023-07-14T16:37:19.073246Z",
     "shell.execute_reply.started": "2023-07-14T16:37:19.066256Z"
    }
   },
   "outputs": [],
   "source": [
    "df['label'] = df['label'].apply(lambda x:list(label_vc.keys())[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T16:37:21.708273Z",
     "iopub.status.busy": "2023-07-14T16:37:21.707100Z",
     "iopub.status.idle": "2023-07-14T16:37:21.735313Z",
     "shell.execute_reply": "2023-07-14T16:37:21.734422Z",
     "shell.execute_reply.started": "2023-07-14T16:37:21.708230Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('sfsfvt10.csv',index=False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
