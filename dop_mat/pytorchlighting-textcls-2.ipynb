{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi\n\nimport os\nimport warnings\nfrom IPython.display import clear_output\n\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:55:05.588117Z","iopub.execute_input":"2023-10-02T19:55:05.588484Z","iopub.status.idle":"2023-10-02T19:55:06.676730Z","shell.execute_reply.started":"2023-10-02T19:55:05.588456Z","shell.execute_reply":"2023-10-02T19:55:06.675380Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Mon Oct  2 19:55:06 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pytorch_lightning as pl\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import accuracy_score\nfrom transformers import AutoModel, DebertaV2Config\nfrom transformers.models.deberta.modeling_deberta import ContextPooler\npl.seed_everything(56)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:55:06.858651Z","iopub.execute_input":"2023-10-02T19:55:06.859066Z","iopub.status.idle":"2023-10-02T19:55:23.037312Z","shell.execute_reply.started":"2023-10-02T19:55:06.859009Z","shell.execute_reply":"2023-10-02T19:55:23.036392Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"56"},"metadata":{}}]},{"cell_type":"code","source":"class CFG:\n    wandb=False\n    num_workers=4\n    model=\"ai-forever/ruElectra-medium\"\n    train_path='/kaggle/input/olympii0930/train.csv'\n    test_path = '/kaggle/input/olympii0930/test.csv'\n    hidden_size = 576\n    pooler_hidden_size = 576\n    pooler_hidden_act = 'gelu'\n    pooler_dropout = 0.1\n    val_split_size = 0.2\n    num_labels = 2\n    scheduler='cosine'\n    max_epoches=15\n    lr=2e-5\n    min_lr=5e-6\n    eps=1e-6\n    betas=(0.9, 0.999)\n    batch_size=16\n    weight_decay=0.0\n    gradient_accumulation_steps=1\n    seed=56","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:55:23.039140Z","iopub.execute_input":"2023-10-02T19:55:23.040101Z","iopub.status.idle":"2023-10-02T19:55:23.046355Z","shell.execute_reply.started":"2023-10-02T19:55:23.040044Z","shell.execute_reply":"2023-10-02T19:55:23.045440Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class ReceiptsDataset(torch.utils.data.Dataset):\n    def __init__(self, df):\n        super().__init__()\n        self.cfg = CFG()\n        self.data = df[['text','label']]\n        self.data = self.data.values\n        self.embedings = []\n        self.tokenizer = AutoTokenizer.from_pretrained(self.cfg.model)\n    def __getitem__(self, index):\n        text = self.data[index][0]\n        label = self.data[index][1]\n        text_encode = self.tokenizer.encode_plus(text, padding='max_length',max_length=128, truncation=True, return_tensors='pt')\n        return text_encode['input_ids'][0],text_encode['attention_mask'][0],label\n    def __len__(self):\n        return len(self.data)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:55:23.048134Z","iopub.execute_input":"2023-10-02T19:55:23.048673Z","iopub.status.idle":"2023-10-02T19:55:23.063784Z","shell.execute_reply.started":"2023-10-02T19:55:23.048640Z","shell.execute_reply":"2023-10-02T19:55:23.062808Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def make_df(data):\n    df = []\n    for score,text in zip(data.Score,data.Text):\n        df += [{'text':text,'label':1 if score == \"Positive\" else 0}]\n    return pd.DataFrame(df)\ndef prepare_text(x:str):\n    x = x.strip().lower()\n    return x","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:55:23.066344Z","iopub.execute_input":"2023-10-02T19:55:23.066681Z","iopub.status.idle":"2023-10-02T19:55:23.076391Z","shell.execute_reply.started":"2023-10-02T19:55:23.066649Z","shell.execute_reply":"2023-10-02T19:55:23.075502Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class ReceiptsDataModule(pl.LightningDataModule):\n    def __init__(self,):\n        super().__init__()\n        self.cfg = CFG()\n        self.train_dataset_path = self.cfg.train_path\n        self.test_dataset_path = self.cfg.test_path\n        self.val_split_size = self.cfg.val_split_size\n        self.batch_size = self.cfg.batch_size\n        self.num_workers = self.cfg.num_workers\n        self.is_setup = False\n    def prepare_data(self):\n        self.train_df = make_df(pd.read_csv(self.train_dataset_path,delimiter='\t'))\n        self.train_df['text'] = self.train_df['text'].apply(prepare_text)\n        self.test_df = pd.read_csv(self.test_dataset_path,delimiter='\t')\n        self.test_df['Score'] = 0\n        self.test_df = make_df(self.test_df)\n        self.test_df['text'] = self.test_df['text'].apply(prepare_text)\n        \n    def setup(self, stage: str):\n        if self.is_setup:\n            return None\n        self.train_df, self.val_df = train_test_split(self.train_df, test_size=self.val_split_size,random_state=self.cfg.seed)\n        self.train_dataset = ReceiptsDataset(self.train_df)\n        self.val_dataset = ReceiptsDataset(self.val_df)\n        self.predict_dataset = ReceiptsDataset(self.test_df)\n        self.is_setup = True\n    \n    def train_dataloader(self):\n        return torch.utils.data.DataLoader(self.train_dataset,\n                                           batch_size=self.batch_size,\n                                           num_workers=self.num_workers,\n                                           shuffle=True)\n    def val_dataloader(self):\n        return torch.utils.data.DataLoader(self.val_dataset,\n                                           batch_size=self.batch_size,\n                                           num_workers=self.num_workers)\n\n    def predict_dataloader(self):\n        return torch.utils.data.DataLoader(self.predict_dataset,\n                                           batch_size=self.batch_size,\n                                           num_workers=self.num_workers,\n                                           shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:55:23.077765Z","iopub.execute_input":"2023-10-02T19:55:23.078352Z","iopub.status.idle":"2023-10-02T19:55:23.093468Z","shell.execute_reply.started":"2023-10-02T19:55:23.078320Z","shell.execute_reply":"2023-10-02T19:55:23.092464Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class MeanPooling(nn.Module):\n    def __init__(self):\n        super(MeanPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        return mean_embeddings\n    \nclass ReceiptsModule(pl.LightningModule):\n    def __init__(self,):\n        super().__init__()\n        self.cfg = CFG()\n        self.bert_encoder = AutoModel.from_pretrained(self.cfg.model)\n        #self.mlp = nn.Sequential(nn.Linear(768,768*2),\n        #                         nn.LayerNorm(768*2),\n        #                         nn.ReLU(),\n        #                         nn.Linear(768*2,self.cfg.num_labels))\n        self.mlp = nn.Linear(self.cfg.hidden_size,self.cfg.num_labels)\n        #self.pool = MeanPooling()\n        self.pool = ContextPooler(self.cfg)\n        self.criterion = nn.CrossEntropyLoss()\n        self.val_targets = []\n        self.val_preds = []\n        self.get_features = False\n    def get_textual_features(self,input_ids,attention_mask):\n        return self.bert_encoder(input_ids=input_ids,\n                                 attention_mask=attention_mask).last_hidden_state\n    def forward(self, x1,x2):\n        #features = self.pool(self.get_textual_features(x1,x2),x2)\n        features = self.pool(self.get_textual_features(x1,x2))\n        return self.mlp(features)\n    \n    def training_step(self, batch, _):\n        x1,x2, targets = batch\n        logits = self(x1,x2)\n        loss = self.criterion(logits, targets)\n        return loss\n        \n    def validation_step(self, batch, _):\n        x1,x2, targets = batch\n        logits = self(x1,x2).argmax(dim=-1).cpu().detach().tolist()\n        self.val_targets += targets.tolist()\n        self.val_preds += logits\n        \n    def predict_step(self, batch, _):\n        x1,x2, _ = batch\n        if not self.get_features:\n            logits = self(x1,x2).argmax(dim=-1).cpu().detach().tolist()\n            return logits\n        else:\n            features = self.pool(self.get_textual_features(x1,x2),x2).cpu().detach().tolist()\n            return features\n        \n    def calc_metric(self):\n        return 2*accuracy_score(self.val_targets,self.val_preds) -1\n        \n    def on_validation_epoch_end(self):\n        print(self.calc_metric())\n        self.val_targets, self.val_preds = [],[]\n        assert 1 == 2\n            \n    def configure_optimizers(self):\n        return torch.optim.AdamW(self.parameters(),\n                                 self.cfg.lr,\n                                 weight_decay=self.cfg.weight_decay,\n                                 betas = self.cfg.betas\n                                )","metadata":{"execution":{"iopub.status.busy":"2023-10-30T13:45:56.226437Z","iopub.execute_input":"2023-10-30T13:45:56.226740Z","iopub.status.idle":"2023-10-30T13:45:56.645160Z","shell.execute_reply.started":"2023-10-30T13:45:56.226713Z","shell.execute_reply":"2023-10-30T13:45:56.643836Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMeanPooling\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(MeanPooling, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n","\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"],"ename":"NameError","evalue":"name 'nn' is not defined","output_type":"error"}]},{"cell_type":"code","source":"dm = ReceiptsDataModule()\ndm.prepare_data()\ndm.setup(0)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:55:23.112995Z","iopub.execute_input":"2023-10-02T19:55:23.113594Z","iopub.status.idle":"2023-10-02T19:55:26.600912Z","shell.execute_reply.started":"2023-10-02T19:55:23.113564Z","shell.execute_reply":"2023-10-02T19:55:26.599812Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0da3a833343d43a99f3e2f0b581e8cf4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/909k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a94f641b3cb8421f9ac603fe0e796fda"}},"metadata":{}}]},{"cell_type":"code","source":"model = ReceiptsModule()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:58:04.098380Z","iopub.execute_input":"2023-10-02T19:58:04.098723Z","iopub.status.idle":"2023-10-02T19:58:11.640407Z","shell.execute_reply.started":"2023-10-02T19:58:04.098696Z","shell.execute_reply":"2023-10-02T19:58:11.639329Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/356M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39e01af946c94c8e999659f27e4dcc11"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at ai-forever/ruElectra-medium were not used when initializing ElectraModel: ['generator.encoder.layer.7.attention.self.query.weight', 'generator.encoder.layer.10.output.dense.bias', 'generator.encoder.layer.3.attention.output.dense.bias', 'generator.encoder.layer.2.attention.self.value.weight', 'generator.encoder.layer.9.attention.output.LayerNorm.bias', 'generator.encoder.layer.1.output.LayerNorm.bias', 'generator.encoder.layer.0.attention.self.value.weight', 'generator.encoder.layer.5.attention.output.LayerNorm.bias', 'generator.embeddings_project.weight', 'generator.encoder.layer.8.attention.output.LayerNorm.bias', 'generator.encoder.layer.7.attention.self.query.bias', 'generator.encoder.layer.6.output.dense.bias', 'generator.encoder.layer.8.intermediate.dense.bias', 'generator.encoder.layer.3.intermediate.dense.bias', 'generator.encoder.layer.0.attention.output.LayerNorm.weight', 'generator.encoder.layer.8.output.dense.weight', 'generator.encoder.layer.2.attention.self.query.weight', 'generator.encoder.layer.1.attention.output.dense.bias', 'generator.encoder.layer.3.attention.output.LayerNorm.weight', 'generator.encoder.layer.8.output.LayerNorm.bias', 'generator.encoder.layer.3.attention.self.query.bias', 'generator_predictions.LayerNorm.weight', 'generator.encoder.layer.5.attention.self.value.weight', 'generator.encoder.layer.11.intermediate.dense.bias', 'generator.encoder.layer.2.output.dense.weight', 'generator.encoder.layer.2.intermediate.dense.bias', 'generator.encoder.layer.6.attention.output.LayerNorm.bias', 'generator.encoder.layer.7.output.LayerNorm.bias', 'generator.encoder.layer.8.attention.output.dense.weight', 'generator.encoder.layer.3.attention.self.key.weight', 'generator.encoder.layer.1.attention.self.value.weight', 'generator.encoder.layer.1.attention.self.key.weight', 'generator.encoder.layer.0.attention.output.dense.weight', 'generator.encoder.layer.0.attention.output.LayerNorm.bias', 'generator_predictions.dense.bias', 'generator.encoder.layer.11.attention.self.value.bias', 'generator.encoder.layer.10.attention.output.LayerNorm.weight', 'generator.encoder.layer.10.attention.self.query.weight', 'generator.encoder.layer.4.attention.output.dense.bias', 'generator.encoder.layer.4.attention.self.query.bias', 'generator.encoder.layer.11.attention.self.value.weight', 'generator.encoder.layer.6.attention.output.dense.bias', 'generator.encoder.layer.0.attention.self.key.weight', 'generator.encoder.layer.4.attention.output.LayerNorm.weight', 'generator.encoder.layer.2.attention.output.dense.weight', 'generator.encoder.layer.3.output.dense.weight', 'generator.encoder.layer.1.attention.output.dense.weight', 'generator.encoder.layer.10.attention.output.LayerNorm.bias', 'discriminator_predictions.classifier.weight', 'generator.encoder.layer.0.output.LayerNorm.weight', 'generator.encoder.layer.11.output.LayerNorm.bias', 'generator.encoder.layer.9.output.dense.weight', 'generator.encoder.layer.5.attention.self.query.weight', 'generator.encoder.layer.6.intermediate.dense.weight', 'generator.encoder.layer.0.attention.self.value.bias', 'generator.encoder.layer.4.attention.self.query.weight', 'generator.encoder.layer.4.attention.self.value.bias', 'generator.encoder.layer.5.output.dense.bias', 'generator.encoder.layer.11.attention.self.key.bias', 'generator.encoder.layer.11.attention.self.query.bias', 'generator.encoder.layer.3.attention.self.query.weight', 'generator.encoder.layer.8.attention.self.query.bias', 'generator.encoder.layer.7.output.dense.bias', 'generator.encoder.layer.5.attention.self.value.bias', 'generator.encoder.layer.6.attention.self.value.weight', 'generator.encoder.layer.10.attention.output.dense.weight', 'generator.encoder.layer.7.attention.self.key.bias', 'generator.encoder.layer.2.output.LayerNorm.weight', 'generator.encoder.layer.0.attention.self.query.weight', 'generator.encoder.layer.5.output.LayerNorm.weight', 'generator.encoder.layer.10.output.dense.weight', 'generator.encoder.layer.4.intermediate.dense.weight', 'generator.encoder.layer.9.attention.self.key.weight', 'generator.encoder.layer.5.attention.output.LayerNorm.weight', 'generator.encoder.layer.8.attention.output.LayerNorm.weight', 'generator.encoder.layer.8.attention.self.key.weight', 'generator.encoder.layer.2.attention.self.query.bias', 'generator.encoder.layer.2.attention.output.LayerNorm.weight', 'generator.encoder.layer.0.attention.output.dense.bias', 'generator.encoder.layer.0.intermediate.dense.bias', 'generator.encoder.layer.5.attention.self.query.bias', 'generator.encoder.layer.2.attention.self.key.bias', 'generator.encoder.layer.7.attention.self.key.weight', 'generator.encoder.layer.6.output.LayerNorm.weight', 'generator.encoder.layer.8.output.LayerNorm.weight', 'generator.encoder.layer.10.output.LayerNorm.weight', 'generator.encoder.layer.9.attention.self.value.weight', 'generator.encoder.layer.9.attention.output.LayerNorm.weight', 'generator.encoder.layer.8.intermediate.dense.weight', 'generator.encoder.layer.6.attention.self.key.bias', 'generator.encoder.layer.11.attention.self.key.weight', 'generator.encoder.layer.2.output.dense.bias', 'generator.encoder.layer.5.attention.output.dense.weight', 'generator.encoder.layer.4.attention.self.key.weight', 'discriminator_predictions.LayerNorm.weight', 'generator.encoder.layer.9.output.LayerNorm.weight', 'generator_predictions.decoder.weight', 'generator.encoder.layer.11.attention.self.query.weight', 'generator.encoder.layer.3.attention.self.key.bias', 'generator.encoder.layer.9.attention.self.key.bias', 'generator.encoder.layer.6.attention.self.value.bias', 'generator.encoder.layer.4.attention.self.value.weight', 'generator.encoder.layer.11.intermediate.dense.weight', 'generator.encoder.layer.7.intermediate.dense.weight', 'generator_predictions.LayerNorm.bias', 'discriminator_predictions.LayerNorm.bias', 'generator.encoder.layer.11.attention.output.LayerNorm.bias', 'generator.embeddings.LayerNorm.bias', 'generator.encoder.layer.4.intermediate.dense.bias', 'generator.encoder.layer.9.attention.self.value.bias', 'generator.encoder.layer.1.intermediate.dense.weight', 'generator.encoder.layer.3.attention.self.value.bias', 'generator.encoder.layer.2.attention.output.dense.bias', 'generator.encoder.layer.6.attention.self.query.weight', 'generator.encoder.layer.0.output.dense.bias', 'generator.encoder.layer.10.attention.self.key.weight', 'generator.encoder.layer.7.intermediate.dense.bias', 'generator.encoder.layer.11.output.dense.bias', 'generator.encoder.layer.6.output.dense.weight', 'generator.encoder.layer.4.output.LayerNorm.weight', 'generator.encoder.layer.3.output.dense.bias', 'generator.embeddings.token_type_embeddings.weight', 'generator.encoder.layer.1.intermediate.dense.bias', 'generator.encoder.layer.0.intermediate.dense.weight', 'generator.encoder.layer.10.attention.self.value.weight', 'generator_predictions.decoder.bias', 'generator.encoder.layer.11.output.dense.weight', 'generator.encoder.layer.1.attention.output.LayerNorm.weight', 'generator.encoder.layer.2.output.LayerNorm.bias', 'generator.encoder.layer.9.output.LayerNorm.bias', 'generator.encoder.layer.4.attention.self.key.bias', 'generator.encoder.layer.4.output.dense.bias', 'generator.encoder.layer.5.attention.output.dense.bias', 'generator.embeddings.position_embeddings.weight', 'generator.encoder.layer.7.attention.output.dense.weight', 'generator.encoder.layer.8.attention.self.value.weight', 'generator.encoder.layer.7.attention.output.dense.bias', 'generator.encoder.layer.11.attention.output.dense.bias', 'generator.encoder.layer.5.intermediate.dense.weight', 'generator.encoder.layer.0.attention.self.key.bias', 'generator.encoder.layer.7.attention.self.value.bias', 'generator.encoder.layer.7.attention.output.LayerNorm.bias', 'generator.encoder.layer.1.attention.output.LayerNorm.bias', 'generator.encoder.layer.5.intermediate.dense.bias', 'generator.encoder.layer.10.output.LayerNorm.bias', 'generator.encoder.layer.0.attention.self.query.bias', 'generator.encoder.layer.10.intermediate.dense.weight', 'generator.encoder.layer.9.intermediate.dense.weight', 'generator.encoder.layer.5.attention.self.key.bias', 'generator.encoder.layer.4.output.dense.weight', 'generator.encoder.layer.11.attention.output.dense.weight', 'generator.encoder.layer.7.attention.output.LayerNorm.weight', 'generator.embeddings.word_embeddings.weight', 'generator.encoder.layer.9.attention.self.query.weight', 'generator.encoder.layer.0.output.LayerNorm.bias', 'generator.encoder.layer.0.output.dense.weight', 'generator.encoder.layer.3.attention.output.dense.weight', 'generator.encoder.layer.1.output.LayerNorm.weight', 'generator_predictions.dense.weight', 'generator.encoder.layer.6.output.LayerNorm.bias', 'generator.encoder.layer.11.output.LayerNorm.weight', 'generator.encoder.layer.6.attention.output.dense.weight', 'generator.encoder.layer.2.intermediate.dense.weight', 'generator.encoder.layer.1.attention.self.query.bias', 'generator.embeddings_project.bias', 'generator.encoder.layer.4.attention.output.LayerNorm.bias', 'generator.encoder.layer.2.attention.self.key.weight', 'generator.encoder.layer.11.attention.output.LayerNorm.weight', 'generator.encoder.layer.10.intermediate.dense.bias', 'generator.encoder.layer.8.attention.self.value.bias', 'generator.encoder.layer.5.attention.self.key.weight', 'generator.encoder.layer.7.output.dense.weight', 'generator.encoder.layer.6.attention.output.LayerNorm.weight', 'generator.encoder.layer.10.attention.self.query.bias', 'generator.encoder.layer.6.intermediate.dense.bias', 'discriminator_predictions.dense.weight', 'generator.encoder.layer.5.output.LayerNorm.bias', 'generator.embeddings.LayerNorm.weight', 'generator.encoder.layer.9.intermediate.dense.bias', 'generator.encoder.layer.10.attention.self.value.bias', 'generator_predictions.bias', 'generator.encoder.layer.9.output.dense.bias', 'generator.encoder.layer.4.output.LayerNorm.bias', 'generator.encoder.layer.3.intermediate.dense.weight', 'generator.encoder.layer.6.attention.self.key.weight', 'generator.encoder.layer.6.attention.self.query.bias', 'generator.encoder.layer.9.attention.output.dense.weight', 'generator.encoder.layer.8.attention.output.dense.bias', 'generator.encoder.layer.1.attention.self.value.bias', 'generator.encoder.layer.3.output.LayerNorm.bias', 'generator.encoder.layer.9.attention.self.query.bias', 'generator.encoder.layer.1.attention.self.query.weight', 'discriminator_predictions.dense.bias', 'generator.encoder.layer.3.attention.output.LayerNorm.bias', 'generator.encoder.layer.2.attention.self.value.bias', 'generator.encoder.layer.10.attention.output.dense.bias', 'generator.encoder.layer.10.attention.self.key.bias', 'generator.encoder.layer.4.attention.output.dense.weight', 'generator.encoder.layer.3.attention.self.value.weight', 'generator.encoder.layer.8.attention.self.query.weight', 'generator.encoder.layer.1.output.dense.bias', 'generator.encoder.layer.7.attention.self.value.weight', 'discriminator_predictions.classifier.bias', 'generator.encoder.layer.7.output.LayerNorm.weight', 'generator.encoder.layer.3.output.LayerNorm.weight', 'generator.encoder.layer.5.output.dense.weight', 'generator.encoder.layer.9.attention.output.dense.bias', 'generator.encoder.layer.1.attention.self.key.bias', 'generator.encoder.layer.8.output.dense.bias', 'generator.encoder.layer.8.attention.self.key.bias', 'generator.encoder.layer.2.attention.output.LayerNorm.bias', 'generator.encoder.layer.1.output.dense.weight']\n- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"logger = pl.loggers.TensorBoardLogger(\"tb_logs\", name=\"text_cls\")\ntrainer = pl.Trainer(\n    accelerator=\"gpu\",\n    logger=logger,\n    max_epochs=15,\n    log_every_n_steps=1\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:58:15.842168Z","iopub.execute_input":"2023-10-02T19:58:15.842501Z","iopub.status.idle":"2023-10-02T19:58:16.608088Z","shell.execute_reply.started":"2023-10-02T19:58:15.842477Z","shell.execute_reply":"2023-10-02T19:58:16.607056Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"trainer.fit(model, datamodule=dm)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:58:18.248542Z","iopub.execute_input":"2023-10-02T19:58:18.249483Z","iopub.status.idle":"2023-10-02T20:34:18.155861Z","shell.execute_reply.started":"2023-10-02T19:58:18.249430Z","shell.execute_reply":"2023-10-02T20:34:18.154726Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"0.125\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10fe3dfe918d4f07995f60f3a48cbe49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"0.7664285714285715\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"0.7964285714285715\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"0.7885714285714285\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"0.7849999999999999\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"0.7757142857142858\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"0.7614285714285713\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"0.792142857142857\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"0.7985714285714285\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"0.8042857142857143\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"0.8085714285714285\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"0.8135714285714286\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"0.7835714285714286\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"0.8042857142857143\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"0.7857142857142858\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"0.7907142857142857\n","output_type":"stream"}]},{"cell_type":"code","source":"preds = trainer.predict(model,dm.predict_dataloader())","metadata":{"execution":{"iopub.status.busy":"2023-07-17T14:58:03.204468Z","iopub.execute_input":"2023-07-17T14:58:03.204842Z","iopub.status.idle":"2023-07-17T14:59:44.121299Z","shell.execute_reply.started":"2023-07-17T14:58:03.204808Z","shell.execute_reply":"2023-07-17T14:59:44.120097Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Predicting: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22c469b47b34408a80f728076a7907d7"}},"metadata":{}}]},{"cell_type":"code","source":"preds = np.concatenate(preds)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T15:00:37.534024Z","iopub.execute_input":"2023-07-17T15:00:37.535137Z","iopub.status.idle":"2023-07-17T15:00:37.639190Z","shell.execute_reply.started":"2023-07-17T15:00:37.535091Z","shell.execute_reply":"2023-07-17T15:00:37.637823Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 preds = np.concatenate(preds)                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92mconcatenate\u001b[0m:\u001b[94m180\u001b[0m                                                                               \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mValueError: \u001b[0mzero-dimensional arrays cannot be concatenated\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 preds = np.concatenate(preds)                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">concatenate</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">180</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>zero-dimensional arrays cannot be concatenated\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"preds","metadata":{"execution":{"iopub.status.busy":"2023-07-17T15:00:42.032460Z","iopub.execute_input":"2023-07-17T15:00:42.032838Z","iopub.status.idle":"2023-07-17T15:00:42.041032Z","shell.execute_reply.started":"2023-07-17T15:00:42.032807Z","shell.execute_reply":"2023-07-17T15:00:42.040021Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"0       Positive\n1       Negative\n2       Negative\n3       Negative\n4       Negative\n          ...   \n5995    Positive\n5996    Positive\n5997    Negative\n5998    Positive\n5999    Positive\nLength: 6000, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"preds = pd.Series(preds).apply(lambda x:\"Positive\" if x == 1 else \"Negative\")","metadata":{"execution":{"iopub.status.busy":"2023-07-17T15:00:34.590824Z","iopub.execute_input":"2023-07-17T15:00:34.591171Z","iopub.status.idle":"2023-07-17T15:00:34.599998Z","shell.execute_reply.started":"2023-07-17T15:00:34.591142Z","shell.execute_reply":"2023-07-17T15:00:34.599036Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"sample_submit = pd.read_csv('/kaggle/input/olympii0930/sample_submission.csv',delimiter='\t')","metadata":{"execution":{"iopub.status.busy":"2023-07-17T15:00:45.918706Z","iopub.execute_input":"2023-07-17T15:00:45.919168Z","iopub.status.idle":"2023-07-17T15:00:45.939879Z","shell.execute_reply.started":"2023-07-17T15:00:45.919128Z","shell.execute_reply":"2023-07-17T15:00:45.938949Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"sample_submit","metadata":{"execution":{"iopub.status.busy":"2023-07-17T15:00:47.340094Z","iopub.execute_input":"2023-07-17T15:00:47.340603Z","iopub.status.idle":"2023-07-17T15:00:47.363172Z","shell.execute_reply.started":"2023-07-17T15:00:47.340552Z","shell.execute_reply":"2023-07-17T15:00:47.362037Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"        idx     Score\n0     13999  Positive\n1     14000  Positive\n2     14001  Positive\n3     14002  Positive\n4     14003  Positive\n...     ...       ...\n5995  19994  Positive\n5996  19995  Positive\n5997  19996  Positive\n5998  19997  Positive\n5999  19998  Positive\n\n[6000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>idx</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13999</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14000</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14001</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14002</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14003</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5995</th>\n      <td>19994</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>5996</th>\n      <td>19995</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>5997</th>\n      <td>19996</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>5998</th>\n      <td>19997</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>5999</th>\n      <td>19998</td>\n      <td>Positive</td>\n    </tr>\n  </tbody>\n</table>\n<p>6000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import csv\nwith open('submitt.csv', 'w', newline='') as csvfile:\n    spamwriter = csv.writer(csvfile, delimiter='\t')\n    spamwriter.writerow(['idx','Score'])\n    for i, el in zip(sample_submit.idx,preds):\n        spamwriter.writerow([i, el])","metadata":{"execution":{"iopub.status.busy":"2023-07-17T15:00:50.620147Z","iopub.execute_input":"2023-07-17T15:00:50.620518Z","iopub.status.idle":"2023-07-17T15:00:50.639191Z","shell.execute_reply.started":"2023-07-17T15:00:50.620489Z","shell.execute_reply":"2023-07-17T15:00:50.638106Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('/kaggle/working/submitt.csv',delimiter='\t')","metadata":{"execution":{"iopub.status.busy":"2023-07-17T15:00:52.169203Z","iopub.execute_input":"2023-07-17T15:00:52.169556Z","iopub.status.idle":"2023-07-17T15:00:52.189097Z","shell.execute_reply.started":"2023-07-17T15:00:52.169528Z","shell.execute_reply":"2023-07-17T15:00:52.188156Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"        idx     Score\n0     13999  Positive\n1     14000  Negative\n2     14001  Negative\n3     14002  Negative\n4     14003  Negative\n...     ...       ...\n5995  19994  Positive\n5996  19995  Positive\n5997  19996  Negative\n5998  19997  Positive\n5999  19998  Positive\n\n[6000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>idx</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13999</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14000</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14001</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14002</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14003</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5995</th>\n      <td>19994</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>5996</th>\n      <td>19995</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>5997</th>\n      <td>19996</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>5998</th>\n      <td>19997</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>5999</th>\n      <td>19998</td>\n      <td>Positive</td>\n    </tr>\n  </tbody>\n</table>\n<p>6000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}