{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting open_clip_torch\n",
      "  Downloading open_clip_torch-2.23.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytorch_lightning\n",
      "  Downloading pytorch_lightning-2.1.1-py3-none-any.whl (776 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 kB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from open_clip_torch) (1.12.1+cu116)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from open_clip_torch) (3.19.6)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from open_clip_torch) (0.13.1+cu116)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from open_clip_torch) (4.64.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from open_clip_torch) (2022.10.31)\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from open_clip_torch) (0.1.97)\n",
      "Collecting timm\n",
      "  Downloading timm-0.9.10-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m116.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.9/dist-packages (from open_clip_torch) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (1.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (23.0)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (2023.1.0)\n",
      "Collecting torchmetrics>=0.7.0\n",
      "  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (5.4.1)\n",
      "Collecting lightning-utilities>=0.8.0\n",
      "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.9/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.28.2)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.9/dist-packages (from ftfy->open_clip_torch) (0.2.6)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->open_clip_torch) (3.9.0)\n",
      "Collecting safetensors\n",
      "  Downloading safetensors-0.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->open_clip_torch) (9.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.1.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (18.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2.8)\n",
      "Installing collected packages: safetensors, lightning-utilities, ftfy, torchmetrics, timm, pytorch_lightning, open_clip_torch\n",
      "Successfully installed ftfy-6.1.1 lightning-utilities-0.9.0 open_clip_torch-2.23.0 pytorch_lightning-2.1.1 safetensors-0.4.0 timm-0.9.10 torchmetrics-1.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install open_clip_torch pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.21.3)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4\n",
      "  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.64.1)\n",
      "Collecting tokenizers<0.15,>=0.14\n",
      "  Downloading tokenizers-0.14.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m122.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.4.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.16.4\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Installing collected packages: fsspec, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.1.0\n",
      "    Uninstalling fsspec-2023.1.0:\n",
      "      Successfully uninstalled fsspec-2023.1.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.12.0\n",
      "    Uninstalling huggingface-hub-0.12.0:\n",
      "      Successfully uninstalled huggingface-hub-0.12.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.12.1\n",
      "    Uninstalling tokenizers-0.12.1:\n",
      "      Successfully uninstalled tokenizers-0.12.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.21.3\n",
      "    Uninstalling transformers-4.21.3:\n",
      "      Successfully uninstalled transformers-4.21.3\n",
      "Successfully installed fsspec-2023.10.0 huggingface-hub-0.17.3 tokenizers-0.14.1 transformers-4.35.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "import open_clip\n",
    "pl.seed_everything(56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  8 21:42:06 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   38C    P0    53W / 400W |      0MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RN50', 'openai'),\n",
       " ('RN50', 'yfcc15m'),\n",
       " ('RN50', 'cc12m'),\n",
       " ('RN50-quickgelu', 'openai'),\n",
       " ('RN50-quickgelu', 'yfcc15m'),\n",
       " ('RN50-quickgelu', 'cc12m'),\n",
       " ('RN101', 'openai'),\n",
       " ('RN101', 'yfcc15m'),\n",
       " ('RN101-quickgelu', 'openai'),\n",
       " ('RN101-quickgelu', 'yfcc15m'),\n",
       " ('RN50x4', 'openai'),\n",
       " ('RN50x16', 'openai'),\n",
       " ('RN50x64', 'openai'),\n",
       " ('ViT-B-32', 'openai'),\n",
       " ('ViT-B-32', 'laion400m_e31'),\n",
       " ('ViT-B-32', 'laion400m_e32'),\n",
       " ('ViT-B-32', 'laion2b_e16'),\n",
       " ('ViT-B-32', 'laion2b_s34b_b79k'),\n",
       " ('ViT-B-32', 'datacomp_xl_s13b_b90k'),\n",
       " ('ViT-B-32', 'datacomp_m_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_clip_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_laion_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_image_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_text_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_basic_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_s128m_b4k'),\n",
       " ('ViT-B-32', 'datacomp_s_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_clip_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_laion_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_image_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_text_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_basic_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_s13m_b4k'),\n",
       " ('ViT-B-32-256', 'datacomp_s34b_b86k'),\n",
       " ('ViT-B-32-quickgelu', 'openai'),\n",
       " ('ViT-B-32-quickgelu', 'laion400m_e31'),\n",
       " ('ViT-B-32-quickgelu', 'laion400m_e32'),\n",
       " ('ViT-B-32-quickgelu', 'metaclip_400m'),\n",
       " ('ViT-B-32-quickgelu', 'metaclip_fullcc'),\n",
       " ('ViT-B-16', 'openai'),\n",
       " ('ViT-B-16', 'laion400m_e31'),\n",
       " ('ViT-B-16', 'laion400m_e32'),\n",
       " ('ViT-B-16', 'laion2b_s34b_b88k'),\n",
       " ('ViT-B-16', 'datacomp_xl_s13b_b90k'),\n",
       " ('ViT-B-16', 'datacomp_l_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_clip_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_laion_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_image_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_text_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_basic_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_s1b_b8k'),\n",
       " ('ViT-B-16-quickgelu', 'metaclip_400m'),\n",
       " ('ViT-B-16-quickgelu', 'metaclip_fullcc'),\n",
       " ('ViT-B-16-plus-240', 'laion400m_e31'),\n",
       " ('ViT-B-16-plus-240', 'laion400m_e32'),\n",
       " ('ViT-L-14', 'openai'),\n",
       " ('ViT-L-14', 'laion400m_e31'),\n",
       " ('ViT-L-14', 'laion400m_e32'),\n",
       " ('ViT-L-14', 'laion2b_s32b_b82k'),\n",
       " ('ViT-L-14', 'datacomp_xl_s13b_b90k'),\n",
       " ('ViT-L-14', 'commonpool_xl_clip_s13b_b90k'),\n",
       " ('ViT-L-14', 'commonpool_xl_laion_s13b_b90k'),\n",
       " ('ViT-L-14', 'commonpool_xl_s13b_b90k'),\n",
       " ('ViT-L-14-quickgelu', 'metaclip_400m'),\n",
       " ('ViT-L-14-quickgelu', 'metaclip_fullcc'),\n",
       " ('ViT-L-14-336', 'openai'),\n",
       " ('ViT-H-14', 'laion2b_s32b_b79k'),\n",
       " ('ViT-H-14-quickgelu', 'metaclip_fullcc'),\n",
       " ('ViT-g-14', 'laion2b_s12b_b42k'),\n",
       " ('ViT-g-14', 'laion2b_s34b_b88k'),\n",
       " ('ViT-bigG-14', 'laion2b_s39b_b160k'),\n",
       " ('roberta-ViT-B-32', 'laion2b_s12b_b32k'),\n",
       " ('xlm-roberta-base-ViT-B-32', 'laion5b_s13b_b90k'),\n",
       " ('xlm-roberta-large-ViT-H-14', 'frozen_laion5b_s13b_b90k'),\n",
       " ('convnext_base', 'laion400m_s13b_b51k'),\n",
       " ('convnext_base_w', 'laion2b_s13b_b82k'),\n",
       " ('convnext_base_w', 'laion2b_s13b_b82k_augreg'),\n",
       " ('convnext_base_w', 'laion_aesthetic_s13b_b82k'),\n",
       " ('convnext_base_w_320', 'laion_aesthetic_s13b_b82k'),\n",
       " ('convnext_base_w_320', 'laion_aesthetic_s13b_b82k_augreg'),\n",
       " ('convnext_large_d', 'laion2b_s26b_b102k_augreg'),\n",
       " ('convnext_large_d_320', 'laion2b_s29b_b131k_ft'),\n",
       " ('convnext_large_d_320', 'laion2b_s29b_b131k_ft_soup'),\n",
       " ('convnext_xxlarge', 'laion2b_s34b_b82k_augreg'),\n",
       " ('convnext_xxlarge', 'laion2b_s34b_b82k_augreg_rewind'),\n",
       " ('convnext_xxlarge', 'laion2b_s34b_b82k_augreg_soup'),\n",
       " ('coca_ViT-B-32', 'laion2b_s13b_b90k'),\n",
       " ('coca_ViT-B-32', 'mscoco_finetuned_laion2b_s13b_b90k'),\n",
       " ('coca_ViT-L-14', 'laion2b_s13b_b90k'),\n",
       " ('coca_ViT-L-14', 'mscoco_finetuned_laion2b_s13b_b90k'),\n",
       " ('EVA01-g-14', 'laion400m_s11b_b41k'),\n",
       " ('EVA01-g-14-plus', 'merged2b_s11b_b114k'),\n",
       " ('EVA02-B-16', 'merged2b_s8b_b131k'),\n",
       " ('EVA02-L-14', 'merged2b_s4b_b131k'),\n",
       " ('EVA02-L-14-336', 'merged2b_s6b_b61k'),\n",
       " ('EVA02-E-14', 'laion2b_s4b_b115k'),\n",
       " ('EVA02-E-14-plus', 'laion2b_s9b_b144k'),\n",
       " ('ViT-B-16-SigLIP', 'webli'),\n",
       " ('ViT-B-16-SigLIP-256', 'webli'),\n",
       " ('ViT-B-16-SigLIP-i18n-256', 'webli'),\n",
       " ('ViT-B-16-SigLIP-384', 'webli'),\n",
       " ('ViT-B-16-SigLIP-512', 'webli'),\n",
       " ('ViT-L-16-SigLIP-256', 'webli'),\n",
       " ('ViT-L-16-SigLIP-384', 'webli'),\n",
       " ('ViT-SO400M-14-SigLIP', 'webli'),\n",
       " ('ViT-SO400M-14-SigLIP-384', 'webli'),\n",
       " ('ViT-L-14-CLIPA', 'datacomp1b'),\n",
       " ('ViT-L-14-CLIPA-336', 'datacomp1b'),\n",
       " ('ViT-H-14-CLIPA', 'datacomp1b'),\n",
       " ('ViT-H-14-CLIPA-336', 'laion2b'),\n",
       " ('ViT-H-14-CLIPA-336', 'datacomp1b'),\n",
       " ('ViT-bigG-14-CLIPA', 'datacomp1b'),\n",
       " ('ViT-bigG-14-CLIPA-336', 'datacomp1b'),\n",
       " ('nllb-clip-base', 'v1'),\n",
       " ('nllb-clip-large', 'v1')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_clip.list_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    wandb=False\n",
    "    num_workers=8\n",
    "    model=\"xlm-roberta-base-ViT-B-32\"\n",
    "    pretrained = \"laion5b_s13b_b90k\"\n",
    "    #model = 'ViT-B-32'\n",
    "    #pretrained = 'commonpool_m_clip_s128m_b4k'\n",
    "    hidden_size = 1024\n",
    "    train_path='./train-test-csvs/train-7.csv'\n",
    "    test_path = './train-test-csvs/test-5.csv'\n",
    "    val_split_size = 0.2\n",
    "    num_labels = 8\n",
    "    scheduler='cosine'\n",
    "    max_epoches=1\n",
    "    clip_lr = 1e-5\n",
    "    mlp_lr = 5e-5\n",
    "    text_lr = 2e-5\n",
    "    eps=1e-6\n",
    "    weights_decay=0.01\n",
    "    batch_size=16\n",
    "    seed=56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df,preprocess,tokenizer):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG()\n",
    "        self.data = df[['image','text']]\n",
    "        self.data = self.data.values\n",
    "        self.processor = preprocess\n",
    "        self.tokenizer = tokenizer\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.data[index][0])\n",
    "        image = self.processor(image)\n",
    "        text = self.tokenizer(self.data[index][1])\n",
    "        return image,text[0],\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "label_vc = {'Развлечения и юмор':0,\n",
    "            'Кулинария':1,\n",
    "            'Торговля и объявления':2,\n",
    "            'СМИ':3,\n",
    "            'Философия и религия':4,\n",
    "            'Животные':5,\n",
    "            'Творчество и дизайн':6,\n",
    "            'Путешествия':7}\n",
    "\n",
    "def process_labels(label):\n",
    "    if label not in label_vc.keys():\n",
    "        return -1\n",
    "    else:\n",
    "        return label_vc[label]\n",
    "def process_text(text:str):\n",
    "    return text.strip().lower()\n",
    "\n",
    "def make_df(path):\n",
    "    df = pd.DataFrame()\n",
    "    data = pd.read_csv(path,sep=';')\n",
    "    if 'label' in data.columns:\n",
    "        df['text'] = data['description'].fillna('')\n",
    "        df['image'] = data['id'].map(lambda x:'./vseros-final-data/Data/Train/'+str(x))\n",
    "        df = df[df['text'] != ''].reset_index(drop=True)\n",
    "    else:\n",
    "        df['text'] = data['description'].fillna('')\n",
    "        df['image'] = data['id'].map(lambda x:'./vseros-final-data/Data/Test/'+str(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,processor,tokenizer):\n",
    "        super().__init__()\n",
    "        self.processor = processor\n",
    "        self.tokenizer = tokenizer\n",
    "        self.cfg = CFG()\n",
    "        self.train_dataset_path = self.cfg.train_path\n",
    "        self.test_dataset_path = self.cfg.test_path\n",
    "        self.val_split_size = self.cfg.val_split_size\n",
    "        self.batch_size = self.cfg.batch_size\n",
    "        self.num_workers = self.cfg.num_workers\n",
    "        self.is_setup = False\n",
    "    def prepare_data(self):\n",
    "        self.train_df = make_df(self.train_dataset_path)\n",
    "        self.test_df = make_df(self.test_dataset_path)\n",
    "    def setup(self, stage: str):\n",
    "        if self.is_setup:\n",
    "            return None\n",
    "        self.train_df, self.val_df = train_test_split(self.train_df, test_size=self.val_split_size,random_state=self.cfg.seed)\n",
    "        self.train_dataset = PLDataset(self.train_df,self.processor,self.tokenizer)\n",
    "        self.val_dataset = PLDataset(self.val_df,self.processor,self.tokenizer)\n",
    "        self.predict_dataset = PLDataset(self.test_df,self.processor,self.tokenizer)\n",
    "        self.is_setup = True\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train_dataset,\n",
    "                                           batch_size=self.batch_size,\n",
    "                                           num_workers=self.num_workers,\n",
    "                                           shuffle=True)\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.val_dataset,\n",
    "                                           batch_size=self.batch_size,\n",
    "                                           num_workers=self.num_workers)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.predict_dataset,\n",
    "                                           batch_size=self.batch_size,\n",
    "                                           num_workers=self.num_workers,\n",
    "                                           shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLModule(pl.LightningModule):\n",
    "    def __init__(self,clip):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG()\n",
    "        self.clip = clip\n",
    "        self.criterion = open_clip.ClipLoss()\n",
    "        self.losses = []\n",
    "        self.get_features = False\n",
    "        \n",
    "    def get_clip_features(self,x1,x2):\n",
    "        return self.clip(x1,x2)\n",
    "    \n",
    "    def forward(self,x1,x2):\n",
    "        features = self.get_clip_features(x1,x2)\n",
    "        return features\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        x1,x2, = batch\n",
    "        out = self(x1,x2)\n",
    "        loss = self.criterion(*out)\n",
    "        return loss\n",
    "        \n",
    "    def validation_step(self, batch, _):\n",
    "        x1,x2, = batch\n",
    "        out = self(x1,x2)\n",
    "        loss = self.criterion(*out)\n",
    "        self.losses += [loss.item()]\n",
    "        \n",
    "    def on_validation_epoch_end(self):\n",
    "        print(np.mean(self.losses))\n",
    "        self.losses = []\n",
    "            \n",
    "    def configure_optimizers(self):\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in self.clip.visual.named_parameters()],\n",
    "                \"lr\": self.cfg.clip_lr\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in self.clip.text.named_parameters()],\n",
    "                \"lr\": self.cfg.clip_lr\n",
    "            },\n",
    "            #{\n",
    "            #    \"params\": [p for n, p in self.mlp.named_parameters()],\n",
    "            #    \"lr\": self.cfg.mlp_lr\n",
    "            #}\n",
    "        ]\n",
    "        return torch.optim.AdamW(optimizer_grouped_parameters,\n",
    "                                 weight_decay=self.cfg.weights_decay\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clip, _, preprocess = open_clip.create_model_and_transforms(CFG.model, pretrained=CFG.pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = open_clip.get_tokenizer(CFG.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dm = PLDataModule(preprocess,tokenizer)\n",
    "dm.prepare_data()\n",
    "dm.setup(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dm.train_dataloader():break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_pl = PLModule(clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval='epoch')\n",
    "checkpoint_cb = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath='./outputs/',\n",
    "    filename='model_{epoch:02d}-{val_acc:.4f}',\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    precision=32,\n",
    "    min_epochs=1,\n",
    "    check_val_every_n_epoch=1,\n",
    "    max_epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | clip      | CustomTextCLIP | 366 M \n",
      "1 | criterion | ClipLoss       | 0     \n",
      "---------------------------------------------\n",
      "366 M     Trainable params\n",
      "0         Non-trainable params\n",
      "366 M     Total params\n",
      "1,464.486 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8562544584274292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6dcf9d2a7e4426a7fed1c4991fc9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.778893924768894\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8868007114337336\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9734414493845355\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0787415006949055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1285426563793612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model_pl,datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T16:36:30.623136Z",
     "iopub.status.busy": "2023-07-14T16:36:30.622725Z",
     "iopub.status.idle": "2023-07-14T16:37:10.405880Z",
     "shell.execute_reply": "2023-07-14T16:37:10.404604Z",
     "shell.execute_reply.started": "2023-07-14T16:36:30.623100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7c5851ec7849b1834bd4a4686aeaa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_preds = trainer.predict(model_pl,datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T16:37:17.768436Z",
     "iopub.status.busy": "2023-07-14T16:37:17.767996Z",
     "iopub.status.idle": "2023-07-14T16:37:17.775830Z",
     "shell.execute_reply": "2023-07-14T16:37:17.774714Z",
     "shell.execute_reply.started": "2023-07-14T16:37:17.768380Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T16:37:18.059174Z",
     "iopub.status.busy": "2023-07-14T16:37:18.058783Z",
     "iopub.status.idle": "2023-07-14T16:37:18.088758Z",
     "shell.execute_reply": "2023-07-14T16:37:18.087727Z",
     "shell.execute_reply.started": "2023-07-14T16:37:18.059143Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "df['label'] = np.sum(test_preds)\n",
    "df['id'] = pd.read_csv(CFG.test_path,sep=';').id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T16:37:19.066294Z",
     "iopub.status.busy": "2023-07-14T16:37:19.065529Z",
     "iopub.status.idle": "2023-07-14T16:37:19.074423Z",
     "shell.execute_reply": "2023-07-14T16:37:19.073246Z",
     "shell.execute_reply.started": "2023-07-14T16:37:19.066256Z"
    }
   },
   "outputs": [],
   "source": [
    "df['label'] = df['label'].apply(lambda x:list(label_vc.keys())[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T16:37:21.708273Z",
     "iopub.status.busy": "2023-07-14T16:37:21.707100Z",
     "iopub.status.idle": "2023-07-14T16:37:21.735313Z",
     "shell.execute_reply": "2023-07-14T16:37:21.734422Z",
     "shell.execute_reply.started": "2023-07-14T16:37:21.708230Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('sfsfvt10.csv',index=False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
