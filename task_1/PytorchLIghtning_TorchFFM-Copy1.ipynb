{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T18:10:40.253207Z",
     "iopub.status.busy": "2023-11-05T18:10:40.252504Z",
     "iopub.status.idle": "2023-11-05T18:10:41.073655Z",
     "shell.execute_reply": "2023-11-05T18:10:41.072827Z",
     "shell.execute_reply.started": "2023-11-05T18:10:40.253179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  5 18:10:40 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   28C    P0    57W / 400W |      0MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from IPython.display import clear_output\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T18:10:42.638209Z",
     "iopub.status.busy": "2023-11-05T18:10:42.637602Z",
     "iopub.status.idle": "2023-11-05T18:10:45.664022Z",
     "shell.execute_reply": "2023-11-05T18:10:45.663397Z",
     "shell.execute_reply.started": "2023-11-05T18:10:42.638180Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pytorch_lightning torchfm\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T18:11:03.129925Z",
     "iopub.status.busy": "2023-11-05T18:11:03.129166Z",
     "iopub.status.idle": "2023-11-05T18:11:05.349145Z",
     "shell.execute_reply": "2023-11-05T18:11:05.348567Z",
     "shell.execute_reply.started": "2023-11-05T18:11:03.129895Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from transformers import AutoTokenizer\n",
    "from torchfm.model.dfm import DeepFactorizationMachineModel\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "pl.seed_everything(56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T18:11:05.350540Z",
     "iopub.status.busy": "2023-11-05T18:11:05.350221Z",
     "iopub.status.idle": "2023-11-05T18:11:05.354497Z",
     "shell.execute_reply": "2023-11-05T18:11:05.353846Z",
     "shell.execute_reply.started": "2023-11-05T18:11:05.350519Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    wandb=False\n",
    "    num_workers=12\n",
    "    train_path='/notebooks/train.gz'\n",
    "    hidden_size = 512\n",
    "    val_split_size = 0.2\n",
    "    num_labels = 2\n",
    "    scheduler='cosine'\n",
    "    max_epoches=15\n",
    "    lr=1e-3\n",
    "    min_lr=5e-6\n",
    "    eps=1e-6\n",
    "    betas=(0.9, 0.999)\n",
    "    batch_size=2048\n",
    "    weight_decay=0.01\n",
    "    gradient_accumulation_steps=1\n",
    "    seed=56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T18:11:05.355714Z",
     "iopub.status.busy": "2023-11-05T18:11:05.355514Z",
     "iopub.status.idle": "2023-11-05T18:11:05.360361Z",
     "shell.execute_reply": "2023-11-05T18:11:05.359629Z",
     "shell.execute_reply.started": "2023-11-05T18:11:05.355695Z"
    }
   },
   "outputs": [],
   "source": [
    "class PLDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df,features,label):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG()\n",
    "        self.data = df\n",
    "        self.features_col = features\n",
    "        self.label_col = label\n",
    "    def __getitem__(self, index):\n",
    "        features = self.data.iloc[index][self.features_col].values.astype(np.int32)\n",
    "        label = self.data.iloc[index][self.label_col]\n",
    "        return features,label\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T18:11:05.899996Z",
     "iopub.status.busy": "2023-11-05T18:11:05.899372Z",
     "iopub.status.idle": "2023-11-05T18:11:05.906809Z",
     "shell.execute_reply": "2023-11-05T18:11:05.906030Z",
     "shell.execute_reply.started": "2023-11-05T18:11:05.899969Z"
    }
   },
   "outputs": [],
   "source": [
    "class PLDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,df,features,label):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG()\n",
    "        self.df = df\n",
    "        self.features = features\n",
    "        self.label = label\n",
    "        self.train_dataset_path = self.cfg.train_path\n",
    "        self.val_split_size = self.cfg.val_split_size\n",
    "        self.batch_size = self.cfg.batch_size\n",
    "        self.num_workers = self.cfg.num_workers\n",
    "        self.is_setup = False\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "    \n",
    "    def setup(self, stage: str):\n",
    "        if self.is_setup:\n",
    "            return None\n",
    "        self.train_df, self.val_df = train_test_split(self.df, test_size=self.val_split_size,random_state=self.cfg.seed)\n",
    "        self.train_dataset = PLDataset(self.train_df,self.features,self.label)\n",
    "        self.val_dataset = PLDataset(self.val_df,self.features,self.label)\n",
    "       # self.predict_dataset = PLDataset(self.test_df,self.features,self.label)\n",
    "        self.is_setup = True\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=self.num_workers,\n",
    "                          shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=self.num_workers)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.predict_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=self.num_workers,\n",
    "                          shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T18:11:06.676362Z",
     "iopub.status.busy": "2023-11-05T18:11:06.675781Z",
     "iopub.status.idle": "2023-11-05T18:11:06.684772Z",
     "shell.execute_reply": "2023-11-05T18:11:06.684074Z",
     "shell.execute_reply.started": "2023-11-05T18:11:06.676334Z"
    }
   },
   "outputs": [],
   "source": [
    "class PLModule(pl.LightningModule):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG()\n",
    "        self.embedings = nn.ModuleList([nn.Embedding(num_emb,emb_dim)\n",
    "                                       for num_emb,emb_dim in zip(self.cfg.embed_num,self.cfg.embed_dim)])\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.cfg.embed_size,self.cfg.hidden_size),\n",
    "                                 nn.GELU(),\n",
    "                                 nn.LayerNorm(self.cfg.hidden_size),\n",
    "                                 nn.Linear(self.cfg.hidden_size,1))\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.val_targets = []\n",
    "        self.val_preds = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = torch.cat([emb(x_i.int()) for emb,x_i in zip(self.embedings,x.T)],dim=-1)\n",
    "        return self.mlp(features).squeeze()\n",
    "    \n",
    "    def training_step(self, batch, _):\n",
    "        x, targets = batch\n",
    "        logits = self(x).to(torch.float64)\n",
    "        loss = self.criterion(logits, targets.to(torch.float64))\n",
    "        return loss\n",
    "        \n",
    "    def validation_step(self, batch, _):\n",
    "        x, targets = batch\n",
    "        logits = self(x).cpu().detach().tolist()\n",
    "        self.val_targets += targets.tolist()\n",
    "        self.val_preds += logits\n",
    "        \n",
    "    def predict_step(self, batch, _):\n",
    "        x, targets = batch\n",
    "        logits = self(x).cpu().detach().tolist()\n",
    "        return logits\n",
    "        \n",
    "    def calc_metric(self):\n",
    "        return roc_auc_score(self.val_targets,self.val_preds)\n",
    "        \n",
    "    def on_validation_epoch_end(self):\n",
    "        print(self.calc_metric())\n",
    "        self.val_targets, self.val_preds = [],[]\n",
    "            \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(),\n",
    "                                 self.cfg.lr,\n",
    "                                 weight_decay=self.cfg.weight_decay,\n",
    "                                 betas = self.cfg.betas\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T18:11:07.848792Z",
     "iopub.status.busy": "2023-11-05T18:11:07.848178Z",
     "iopub.status.idle": "2023-11-05T18:12:43.613642Z",
     "shell.execute_reply": "2023-11-05T18:12:43.612858Z",
     "shell.execute_reply.started": "2023-11-05T18:11:07.848762Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T18:12:58.136782Z",
     "iopub.status.busy": "2023-11-05T18:12:58.136453Z",
     "iopub.status.idle": "2023-11-05T18:12:58.140540Z",
     "shell.execute_reply": "2023-11-05T18:12:58.139917Z",
     "shell.execute_reply.started": "2023-11-05T18:12:58.136758Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_features = ['hour', 'C1', 'banner_pos', 'site_id', 'site_domain',\n",
    "       'site_category', 'app_id', 'app_domain', 'app_category', 'device_id',\n",
    "       'device_ip', 'device_model', 'device_type', 'device_conn_type', 'C14',\n",
    "       'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21']\n",
    "features = cat_features\n",
    "label_col = 'click'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T18:12:59.167274Z",
     "iopub.status.busy": "2023-11-05T18:12:59.166979Z",
     "iopub.status.idle": "2023-11-05T18:12:59.172075Z",
     "shell.execute_reply": "2023-11-05T18:12:59.171434Z",
     "shell.execute_reply.started": "2023-11-05T18:12:59.167251Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultyLabelEncoder():\n",
    "    def __init__(self,cat_cols):\n",
    "        self.cat_cols = cat_cols\n",
    "    \n",
    "    def fit_transform(self,df):\n",
    "        self.encoders = []\n",
    "        for col in tqdm(self.cat_cols):\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "            self.encoders += [le]\n",
    "        return df\n",
    "    \n",
    "    def transform(self,df):\n",
    "        for col,le in tqdm(zip(self.cat_cols,self.encoders),total=len(self.cat_cols)):\n",
    "            df[col] = le.transform(df[col])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T18:13:00.058693Z",
     "iopub.status.busy": "2023-11-05T18:13:00.058406Z",
     "iopub.status.idle": "2023-11-05T18:15:52.006615Z",
     "shell.execute_reply": "2023-11-05T18:15:52.005847Z",
     "shell.execute_reply.started": "2023-11-05T18:13:00.058671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511da3a83d3748b5bd3a9b7ce044abfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "le = MultyLabelEncoder(cat_features)\n",
    "df = le.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T18:15:59.640945Z",
     "iopub.status.busy": "2023-11-05T18:15:59.640623Z",
     "iopub.status.idle": "2023-11-05T18:16:05.126506Z",
     "shell.execute_reply": "2023-11-05T18:16:05.125892Z",
     "shell.execute_reply.started": "2023-11-05T18:15:59.640921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4a1b02e47243eda7697ebddccc5042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CFG.embed_num = [df[col].nunique() for col in tqdm(cat_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T18:16:05.129390Z",
     "iopub.status.busy": "2023-11-05T18:16:05.129217Z",
     "iopub.status.idle": "2023-11-05T18:16:05.132597Z",
     "shell.execute_reply": "2023-11-05T18:16:05.132084Z",
     "shell.execute_reply.started": "2023-11-05T18:16:05.129372Z"
    }
   },
   "outputs": [],
   "source": [
    "CFG.embed_dim = [64] * len(CFG.embed_num)\n",
    "CFG.embed_size = sum(CFG.embed_dim)\n",
    "CFG.hidden_size = CFG.embed_size * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T18:16:05.135384Z",
     "iopub.status.busy": "2023-11-05T18:16:05.135211Z",
     "iopub.status.idle": "2023-11-05T18:16:05.137908Z",
     "shell.execute_reply": "2023-11-05T18:16:05.137382Z",
     "shell.execute_reply.started": "2023-11-05T18:16:05.135367Z"
    }
   },
   "outputs": [],
   "source": [
    "dm = PLDataModule(df,features,label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AFMLayer(nn.Module):\n",
    "    def __init__(self, in_features, attention_factor=4, l2_reg_w=0, dropout_rate=0, seed=1024, device='cpu'):\n",
    "        super(AFMLayer, self).__init__()\n",
    "        self.attention_factor = attention_factor\n",
    "        self.l2_reg_w = l2_reg_w\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.seed = seed\n",
    "        embedding_size = in_features\n",
    "    \n",
    "        self.attention_W = nn.Parameter(torch.Tensor(\n",
    "            embedding_size, self.attention_factor))\n",
    "\n",
    "        self.attention_b = nn.Parameter(torch.Tensor(self.attention_factor))\n",
    "\n",
    "        self.projection_h = nn.Parameter(\n",
    "            torch.Tensor(self.attention_factor, 1))\n",
    "\n",
    "        self.projection_p = nn.Parameter(torch.Tensor(embedding_size, 1))\n",
    "\n",
    "        for tensor in [self.attention_W, self.projection_h, self.projection_p]:\n",
    "            nn.init.xavier_normal_(tensor, )\n",
    "\n",
    "        for tensor in [self.attention_b]:\n",
    "            nn.init.zeros_(tensor, )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embeds_vec_list = inputs\n",
    "        row,col = [],[]\n",
    "\n",
    "        for r, c in itertools.combinations(embeds_vec_list, 2):\n",
    "            row.append(r)\n",
    "            col.append(c)\n",
    "\n",
    "        p = torch.cat(row, dim=1)\n",
    "        q = torch.cat(col, dim=1)\n",
    "        inner_product = p * q\n",
    "\n",
    "        bi_interaction = inner_product\n",
    "        attention_temp = F.relu(torch.tensordot(\n",
    "            bi_interaction, self.attention_W, dims=([-1], [0])) + self.attention_b)\n",
    "\n",
    "        self.normalized_att_score = F.softmax(torch.tensordot(\n",
    "            attention_temp, self.projection_h, dims=([-1], [0])), dim=1)\n",
    "        attention_output = torch.sum(\n",
    "            self.normalized_att_score * bi_interaction, dim=1)\n",
    "\n",
    "        attention_output = self.dropout(attention_output)  # training\n",
    "\n",
    "        afm_out = torch.tensordot(\n",
    "            attention_output, self.projection_p, dims=([-1], [0]))\n",
    "        return afm_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T17:51:09.017752Z",
     "iopub.status.busy": "2023-11-05T17:51:09.017053Z",
     "iopub.status.idle": "2023-11-05T17:51:13.357229Z",
     "shell.execute_reply": "2023-11-05T17:51:13.356628Z",
     "shell.execute_reply.started": "2023-11-05T17:51:09.017725Z"
    }
   },
   "outputs": [],
   "source": [
    "pl_model = PLModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T17:51:14.853197Z",
     "iopub.status.busy": "2023-11-05T17:51:14.852470Z",
     "iopub.status.idle": "2023-11-05T17:51:14.857393Z",
     "shell.execute_reply": "2023-11-05T17:51:14.856955Z",
     "shell.execute_reply.started": "2023-11-05T17:51:14.853170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PLModule(\n",
       "  (embedings): ModuleList(\n",
       "    (0): Embedding(240, 64)\n",
       "    (1): Embedding(7, 64)\n",
       "    (2): Embedding(7, 64)\n",
       "    (3): Embedding(4737, 64)\n",
       "    (4): Embedding(7745, 64)\n",
       "    (5): Embedding(26, 64)\n",
       "    (6): Embedding(8552, 64)\n",
       "    (7): Embedding(559, 64)\n",
       "    (8): Embedding(36, 64)\n",
       "    (9): Embedding(2686408, 64)\n",
       "    (10): Embedding(6729486, 64)\n",
       "    (11): Embedding(8251, 64)\n",
       "    (12): Embedding(5, 64)\n",
       "    (13): Embedding(4, 64)\n",
       "    (14): Embedding(2626, 64)\n",
       "    (15): Embedding(8, 64)\n",
       "    (16): Embedding(9, 64)\n",
       "    (17): Embedding(435, 64)\n",
       "    (18): Embedding(4, 64)\n",
       "    (19): Embedding(68, 64)\n",
       "    (20): Embedding(172, 64)\n",
       "    (21): Embedding(60, 64)\n",
       "  )\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=1408, out_features=2816, bias=True)\n",
       "    (1): GELU(approximate=none)\n",
       "    (2): LayerNorm((2816,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): Linear(in_features=2816, out_features=1, bias=True)\n",
       "  )\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T17:51:26.283922Z",
     "iopub.status.busy": "2023-11-05T17:51:26.283130Z",
     "iopub.status.idle": "2023-11-05T17:51:26.300078Z",
     "shell.execute_reply": "2023-11-05T17:51:26.299503Z",
     "shell.execute_reply.started": "2023-11-05T17:51:26.283895Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "logger = pl.loggers.TensorBoardLogger(\"tb_logs\", name=\"text_cls\")\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    logger=logger,\n",
    "    max_epochs=15,\n",
    "    log_every_n_steps=1,\n",
    "    val_check_interval=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T17:51:26.943929Z",
     "iopub.status.busy": "2023-11-05T17:51:26.943260Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type              | Params\n",
      "------------------------------------------------\n",
      "0 | embedings | ModuleList        | 604 M \n",
      "1 | mlp       | Sequential        | 4.0 M \n",
      "2 | criterion | BCEWithLogitsLoss | 0     \n",
      "------------------------------------------------\n",
      "608 M     Trainable params\n",
      "0         Non-trainable params\n",
      "608 M     Total params\n",
      "2,434.963 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b8e307fcd448ff956d6c708a284fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4561391262436454\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02fe3a03c7c8459aac2fa370574c836d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f2767221dd479f80a6026829977b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7556783052751697\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(pl_model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_loss_forward_reduce_cuda_kernel_2d_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
