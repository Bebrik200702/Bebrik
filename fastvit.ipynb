{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение FastVit+GemPooling+MLP\n",
    "В данной тетрадке расположен код обучения и инференса FastVit модели. Перед использованием кода нужно удостовериться, что все нужные библиотеки установлены и указан ваш wandb_api_key в СFG.wandb_key. Для инференса рекомендуется использовать модель с наименьшим RMSE.\n",
    "\n",
    "Вывод: Данный эксперимент показывает нам, что FastVit модели, не смотря на очень быстрый инференс показывают SOTA результаты среди трансформеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "#!pip install lightning timm opendatasets albumentations catboost gdown open_clip_torch wandb\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from math import sin,cos,pi\n",
    "from sklearn.metrics import accuracy_score,f1_score,balanced_accuracy_score\n",
    "import albumentations as A\n",
    "import open_clip\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from catboost import CatBoostClassifier,Pool,cv\n",
    "from copy import deepcopy\n",
    "import wandb\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "import timm \n",
    "pl.seed_everything(56)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Конфиги:\n",
    "- использована модель `fastvit_ma36` с весами `apple_dist_in1k`\n",
    "- функция активации [PReLU в MLP](../experiments/CLIP_train/experiments.ipynb)\n",
    "- [Cosine Scheduler with warmup](../experiments/CLIP_train/experiments.ipynb)\n",
    "- GeM Pooling\n",
    "- было выбрано оптимальное разделение на обучающую и валидационную выборку: 20%\n",
    "\n",
    "<div>\n",
    "<img src=\"images/FastViT.avif\" width=\"800\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    class data:\n",
    "        train_data= './aiijc23-4/train_scores.csv'\n",
    "        test_data = './simple_sub.csv'\n",
    "        train_path='./aiijc23-4/train/train/'\n",
    "        test_path = './aiijc23-4/test/test/'\n",
    "        num_workers = 4\n",
    "        val_split_size = 0.2\n",
    "        batch_size = 32\n",
    "        seed = 56\n",
    "    class model:\n",
    "        model ='fastvit_ma36.apple_dist_in1k'\n",
    "        pretrained = True\n",
    "        num_labels = 1\n",
    "        scheduler= True\n",
    "        max_epoches = 4\n",
    "        lr = 2e-4\n",
    "        p = 3\n",
    "        eps=1e-6\n",
    "        warmup_step = 0.1\n",
    "        warmup_epoch = 4\n",
    "        num_cycles=0.55\n",
    "        weight_decay= 0.02\n",
    "        betas=(0.9, 0.999)\n",
    "    wandb_key=\"your_key\"\n",
    "    seed=56"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_df(path,root_path=CFG.data.train_path):\n",
    "    data = pd.read_csv(path)\n",
    "    df = pd.DataFrame()\n",
    "    df['image'] = data['IMAGE'].apply(lambda x:root_path + x)\n",
    "    df['label'] = data['SCORE']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLDataset(Dataset):\n",
    "    def __init__(self, df,preprocess):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG.data\n",
    "        self.data = df[['image','label']].values\n",
    "        self.preprocess = preprocess\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.data[index][0]).convert('RGB')\n",
    "        image = self.preprocess(image)\n",
    "        label = self.data[index][1]\n",
    "        return image,label\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,preprocess):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG.data\n",
    "        self.train_dataset_path = self.cfg.train_data\n",
    "        self.test_dataset_path = self.cfg.test_path\n",
    "        self.val_split_size = self.cfg.val_split_size\n",
    "        self.batch_size = self.cfg.batch_size\n",
    "        self.num_workers = self.cfg.num_workers\n",
    "        self.is_setup = False\n",
    "        self.preprocess = preprocess\n",
    "    def prepare_data(self):\n",
    "        self.train_df = make_df(self.train_dataset_path)\n",
    "        self.test_df = make_df(CFG.data.test_data,\n",
    "                               root_path=CFG.data.test_path)\n",
    "        \n",
    "    def setup(self, stage: str):\n",
    "        if self.is_setup:\n",
    "            return None\n",
    "        self.train_df, self.val_df = train_test_split(self.train_df, test_size=self.val_split_size,random_state=self.cfg.seed)\n",
    "        self.train_dataset = PLDataset(self.train_df,self.preprocess)\n",
    "        self.val_dataset = PLDataset(self.val_df,self.preprocess)\n",
    "        self.test_dataset = PLDataset(self.test_df,self.preprocess)\n",
    "        self.is_setup = True\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset,\n",
    "                         batch_size=self.batch_size,\n",
    "                         num_workers=self.num_workers,\n",
    "                         shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=self.num_workers)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.test_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрики и лосс\n",
    "- были использованы различные метрики для создания новых гипотез\n",
    "- была выбрана метрика RMSE, потому что она показывала себя лучше всего на регрессионных метриках\n",
    "$$ RMSE = \\sqrt{\\frac{\\sum_{i=1}^n(pred_i-act_i)^2}{n}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        loss = torch.sqrt(self.mse(yhat,y) + self.eps)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeM Pooling\n",
    "<div>\n",
    "<img src=\"images/GeM-Pooling.png\" width=\"600\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6, requires_grad=True):\n",
    "        super().__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1) * p, requires_grad=requires_grad)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return x.clamp(min=self.eps).pow(self.p).mean((-2, -1)).pow(1.0 / self.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инициализация модели и алгоритм обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PLModule(pl.LightningModule):\n",
    "    def __init__(self,model):\n",
    "        super().__init__()\n",
    "        self.cfg = CFG.model\n",
    "        self.model = model\n",
    "        self.global_pools = nn.ModuleList([GeM(p=self.cfg.p) for _ in range(4)])\n",
    "        self.mlp = nn.Sequential(nn.Linear(1140,1140 // 2),\n",
    "                                 nn.PReLU(),\n",
    "                                 nn.LayerNorm(1140 // 2),\n",
    "                                 nn.Linear(1140 // 2,1),\n",
    "                                )\n",
    "        self.criterion = RMSELoss()\n",
    "        self.last_loss = 0\n",
    "        self.losses = []\n",
    "        \n",
    "    def forward(self,x):\n",
    "        features = self.model(x)\n",
    "        features = torch.cat([global_pool(m) for m, global_pool in zip(features, self.global_pools)], dim=1)\n",
    "        features = self.mlp(features)\n",
    "        return torch.squeeze(features)\n",
    "\n",
    "    def training_step(self, batch, i):\n",
    "        x,targets = batch\n",
    "        x,targets = x.float(),targets.float()\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, targets)\n",
    "        self.log_dict({'train_loss':loss.item()})\n",
    "        self.last_loss = loss.item()\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, batch, i):\n",
    "        x,targets = batch\n",
    "        x,targets = x.float(),targets.float()\n",
    "        logits = self(x)\n",
    "        return logits\n",
    "        \n",
    "    def validation_step(self, batch, _):\n",
    "        x,targets = batch\n",
    "        x,targets = x.float(),targets.float()\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits,targets)\n",
    "        self.log_dict({'val_loss':loss.item()})\n",
    "        self.last_loss = loss.item()\n",
    "    \n",
    "                \n",
    "    def on_validation_epoch_end(self):\n",
    "        self.losses = []\n",
    "            \n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.AdamW(self.parameters(),\n",
    "                                  lr=self.cfg.lr,\n",
    "                                  betas=self.cfg.betas,\n",
    "                                  eps=self.cfg.eps,\n",
    "                                  weight_decay = self.cfg.weight_decay)\n",
    "        \n",
    "        scheduler = get_cosine_schedule_with_warmup(optim,\n",
    "                                                    num_warmup_steps = TRAIN_STEPS * self.cfg.warmup_epoch * self.cfg.warmup_step, \n",
    "                                                    num_training_steps = TRAIN_STEPS * self.cfg.warmup_epoch,\n",
    "                                                    num_cycles = self.cfg.num_cycles)\n",
    "        scheduler = {'scheduler':scheduler,\n",
    "                     'interval':'step',\n",
    "                     'frequency':1}\n",
    "        return  [optim],[scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_config = timm.data.resolve_model_data_config(CFG.model.model)\n",
    "data_config['input_size'] = (3,224,224)\n",
    "processor = timm.data.create_transform(**data_config, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = timm.create_model(CFG.model.model,\n",
    "                          pretrained=CFG.model.pretrained,\n",
    "                          num_classes=0,\n",
    "                          features_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dm = PLDataModule(processor)\n",
    "dm.prepare_data()\n",
    "dm.setup(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_STEPS = len(dm.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl_model = PLModule(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrey20007\u001b[0m (\u001b[33mandrey2007\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20231016_203657-1k4jo35u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andrey2007/AIIJC/runs/1k4jo35u\" target=\"_blank\">fastvit_ma36.apple_dist_in1k + gem_pool + drop=0.1</a></strong> to <a href=\"https://wandb.ai/andrey2007/AIIJC\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/andrey2007/AIIJC/runs/1k4jo35u?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f5f0460e700>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=CFG.wandb_key)\n",
    "os.environ['WANDB_API_KEY'] = CFG.wandb_key\n",
    "wandb.init(project='AIIJC',name='fastvit_ma36_gempooling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval='epoch')\n",
    "checkpoint_cb = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath='./outputs_fastvit/',\n",
    "    filename='model_{epoch:02d}-{val_loss:.4f}',\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    precision=32,\n",
    "    callbacks = [lr_monitor,checkpoint_cb],\n",
    "    logger = pl.loggers.WandbLogger(),\n",
    "    min_epochs=1,\n",
    "    devices=[0],\n",
    "    check_val_every_n_epoch=1,\n",
    "    max_epochs=CFG.model.max_epoches\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(pl_model,datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at outputs/model_epoch=02-val_loss=0.4845.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at outputs/model_epoch=02-val_loss=0.4845.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f303fa09462e4a32bbfeafa257299ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = trainer.predict(pl_model,datamodule=dm,ckpt_path='outputs/model_epoch=02-val_loss=0.4845.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('simple_sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df['SCORE'] = np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.to_csv('fastfit_ma32.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMAGE</th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86cc6e863c9b6bb2a0e0db114c9775aa.jpg</td>\n",
       "      <td>8.019901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>da71671681d9cef5b60727801bf95ef8.jpg</td>\n",
       "      <td>5.779160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>821a9ff5df6e581c68c0371dc6b1eb90.jpg</td>\n",
       "      <td>7.971606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ed842bb42c39fe257ac459b544bb7ba8.jpg</td>\n",
       "      <td>8.025720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6eed69b8f6d62f28b809d9cbafcaab0b.jpg</td>\n",
       "      <td>5.954120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>46aa642bbcfdbed5eed380ba10fdbbbc.jpg</td>\n",
       "      <td>5.189587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>dc737dc9a19844943540816e4488b425.jpg</td>\n",
       "      <td>4.447919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>8038a60dac57ba5d445b99978a36a1d5.jpg</td>\n",
       "      <td>5.550060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>5381dd99c37acb63db903eac293fbe4c.jpg</td>\n",
       "      <td>4.402526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>646b27fbd82b0d5a517e4ebb4b514d6f.jpg</td>\n",
       "      <td>5.173681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9988 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     IMAGE     SCORE\n",
       "0     86cc6e863c9b6bb2a0e0db114c9775aa.jpg  8.019901\n",
       "1     da71671681d9cef5b60727801bf95ef8.jpg  5.779160\n",
       "2     821a9ff5df6e581c68c0371dc6b1eb90.jpg  7.971606\n",
       "3     ed842bb42c39fe257ac459b544bb7ba8.jpg  8.025720\n",
       "4     6eed69b8f6d62f28b809d9cbafcaab0b.jpg  5.954120\n",
       "...                                    ...       ...\n",
       "9983  46aa642bbcfdbed5eed380ba10fdbbbc.jpg  5.189587\n",
       "9984  dc737dc9a19844943540816e4488b425.jpg  4.447919\n",
       "9985  8038a60dac57ba5d445b99978a36a1d5.jpg  5.550060\n",
       "9986  5381dd99c37acb63db903eac293fbe4c.jpg  4.402526\n",
       "9987  646b27fbd82b0d5a517e4ebb4b514d6f.jpg  5.173681\n",
       "\n",
       "[9988 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
